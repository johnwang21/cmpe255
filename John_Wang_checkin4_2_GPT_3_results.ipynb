{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Based on: https://github.com/openai/openai-cookbook/blob/main/examples/Regression_using_embeddings.ipynb\n",
        "and: https://github.com/JiayaoLi00/CMPE255/blob/main/gpt3/resume_classification_gpt3_part4_classification.ipynb"
      ],
      "metadata": {
        "id": "fAUSopnPr-Z2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBatYLTmjjJQ",
        "outputId": "a0bcc010-0d3d-4b71-d6f2-5f4d53f6b72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Using cached openai-0.25.0.tar.gz (44 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=a6588153d0bda18b837a6e8e034683918d3a9db877481f968549d8afa42f4702\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"
          ]
        }
      ],
      "source": [
        "#https://scikit-learn.org/stable/modules/ensemble.html\n",
        "#https://beta.openai.com/docs/guides/embeddings/use-cases\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "from sklearn.metrics import classification_report\n",
        "from openai.embeddings_utils import cosine_similarity, get_embedding\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "data_train_path = '/content/train_with_embedding.csv'\n",
        "data_test_path = '/content/test_with_embedding.csv'\n",
        "\n",
        "df_train = pd.read_csv(data_train_path)\n",
        "df_test = pd.read_csv(data_test_path)\n",
        "\n",
        "openai.api_key = \"sk-key\"\n",
        "\n",
        "df_train['babbage_similarity'] = df_train.babbage_similarity.apply(eval).apply(np.array)\n",
        "df_train['babbage_search'] = df_train.babbage_search.apply(eval).apply(np.array)\n",
        "\n",
        "df_test['babbage_similarity'] = df_test.babbage_similarity.apply(eval).apply(np.array)\n",
        "df_test['babbage_search'] = df_test.babbage_search.apply(eval).apply(np.array)\n",
        "\n",
        "X_train = list(df_train.babbage_similarity.values)\n",
        "X_test = list(df_test.babbage_similarity.values)\n",
        "y_train = df_train.Category\n",
        "y_test = df_test.Category"
      ],
      "metadata": {
        "id": "zvUUVOwfr7Cj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "clf = AdaBoostClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "probas = clf.predict_proba(X_test)\n",
        "\n",
        "report = classification_report(y_test, preds)\n",
        "print(accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eez700T_6G9F",
        "outputId": "cf230aa9-3cef-417a-a9d4-32c1f9c29d55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1903114186851211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "#adopted from https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logreg = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "y_pred_test2 = logreg.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_test2))\n",
        "\n",
        "#0.8131487889273357"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TaNeVi7VmG9",
        "outputId": "180e40bd-b277-41c7-86a1-447a7de12072"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8131487889273357\n"
          ]
        }
      ]
    }
  ]
}
